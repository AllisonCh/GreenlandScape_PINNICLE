2025-01-06 16:07:21.875468: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-01-06 16:07:21.892032: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1736197641.909750 1616648 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1736197641.915160 1616648 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-01-06 16:07:21.934450: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Using backend: tensorflow
Other supported backends: tensorflow.compat.v1, pytorch, jax, paddle.
paddle supports more examples now and is recommended.
Enable just-in-time compilation with XLA.

Disable just-in-time compilation with XLA.
ERROR:root:ERROR: MATLAB type not supported: qmustatistics, (uint32)
ERROR:root:ERROR: MATLAB type not supported: lovenumbers, (uint32)
ERROR:root:ERROR: MATLAB type not supported: rotational, (uint32)
ERROR:root:ERROR: MATLAB type not supported: solidearthsettings, (uint32)
2025-01-06 16:07:25.921152: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
I0000 00:00:1736197645.921388 1616648 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0
Set the default float type to float64
add Fourier feature transform to input transform
add output transform with [-3.1709792e-04 -3.1709792e-04 -3.1709792e-04 -3.1709792e-04
 -1.0000000e+03  1.0000000e+01  1.0000000e-02] and [3.1709792e-04 3.1709792e-04 3.1709792e-04 3.1709792e-04 3.6000000e+03
 3.5000000e+03 1.0000000e+04]
Compiling model...
'compile' took 0.005494 s

Training model...

Step      Train loss                                                                                    Test loss                                                                                     Test metric
0         [2.71e+02, 2.42e+02, 2.21e+02, 1.45e+02, 1.78e+03, 8.12e+02, 4.36e+00, 1.17e+00, 3.58e-02]    [2.71e+02, 2.42e+02, 2.21e+02, 1.45e+02, 1.78e+03, 8.12e+02, 4.36e+00, 1.17e+00, 3.58e-02]    []  
10000     [9.06e-03, 2.98e-03, 2.19e-03, 4.61e-03, 4.72e-03, 1.08e-02, 2.46e-01, 4.35e-01, 1.71e-02]    [9.06e-03, 2.98e-03, 2.19e-03, 4.61e-03, 4.72e-03, 1.08e-02, 2.46e-01, 4.35e-01, 1.71e-02]    []  
20000     [9.84e-03, 1.21e-02, 7.68e-03, 9.58e-03, 3.81e-03, 6.82e-03, 1.89e-02, 2.16e-02, 9.36e-03]    [9.84e-03, 1.21e-02, 7.68e-03, 9.58e-03, 3.81e-03, 6.82e-03, 1.89e-02, 2.16e-02, 9.36e-03]    []  
30000     [5.07e-04, 5.81e-04, 5.65e-04, 5.63e-04, 4.58e-04, 7.63e-04, 6.63e-04, 7.55e-03, 1.74e-03]    [5.07e-04, 5.81e-04, 5.65e-04, 5.63e-04, 4.58e-04, 7.63e-04, 6.63e-04, 7.55e-03, 1.74e-03]    []  
40000     [4.21e-04, 3.02e-04, 5.84e-04, 3.63e-04, 2.77e-04, 3.03e-04, 5.34e-04, 5.40e-03, 3.84e-04]    [4.21e-04, 3.02e-04, 5.84e-04, 3.63e-04, 2.77e-04, 3.03e-04, 5.34e-04, 5.40e-03, 3.84e-04]    []  
50000     [4.78e-04, 2.27e-04, 5.05e-04, 2.32e-04, 2.44e-04, 1.90e-04, 4.88e-04, 4.69e-03, 2.46e-04]    [4.78e-04, 2.27e-04, 5.05e-04, 2.32e-04, 2.44e-04, 1.90e-04, 4.88e-04, 4.69e-03, 2.46e-04]    []  
60000     [1.86e-04, 2.01e-04, 2.36e-04, 1.81e-04, 1.59e-04, 1.61e-04, 4.41e-04, 4.38e-03, 1.98e-04]    [1.86e-04, 2.01e-04, 2.36e-04, 1.81e-04, 1.59e-04, 1.61e-04, 4.41e-04, 4.38e-03, 1.98e-04]    []  
70000     [1.76e-04, 2.01e-04, 1.66e-04, 2.00e-04, 1.44e-04, 1.62e-04, 4.09e-04, 4.19e-03, 1.68e-04]    [1.76e-04, 2.01e-04, 1.66e-04, 2.00e-04, 1.44e-04, 1.62e-04, 4.09e-04, 4.19e-03, 1.68e-04]    []  
80000     [1.60e-04, 1.68e-04, 1.57e-04, 1.70e-04, 1.38e-04, 1.39e-04, 3.90e-04, 4.00e-03, 1.44e-04]    [1.60e-04, 1.68e-04, 1.57e-04, 1.70e-04, 1.38e-04, 1.39e-04, 3.90e-04, 4.00e-03, 1.44e-04]    []  
90000     [5.95e-04, 2.51e-04, 8.10e-04, 2.60e-04, 2.77e-04, 1.45e-04, 3.80e-04, 3.95e-03, 1.32e-04]    [5.95e-04, 2.51e-04, 8.10e-04, 2.60e-04, 2.77e-04, 1.45e-04, 3.80e-04, 3.95e-03, 1.32e-04]    []  
100000    [2.11e-04, 2.20e-04, 2.53e-04, 3.72e-04, 1.44e-04, 1.39e-04, 3.65e-04, 3.92e-03, 1.21e-04]    [2.11e-04, 2.20e-04, 2.53e-04, 3.72e-04, 1.44e-04, 1.39e-04, 3.65e-04, 3.92e-03, 1.21e-04]    []  
110000    [2.12e-04, 2.00e-04, 2.32e-04, 2.04e-04, 1.46e-04, 1.81e-04, 3.53e-04, 3.71e-03, 1.07e-04]    [2.12e-04, 2.00e-04, 2.32e-04, 2.04e-04, 1.46e-04, 1.81e-04, 3.53e-04, 3.71e-03, 1.07e-04]    []  
120000    [1.24e-04, 1.46e-04, 1.30e-04, 1.43e-04, 1.09e-04, 1.11e-04, 3.46e-04, 3.58e-03, 1.02e-04]    [1.24e-04, 1.46e-04, 1.30e-04, 1.43e-04, 1.09e-04, 1.11e-04, 3.46e-04, 3.58e-03, 1.02e-04]    []  
130000    [2.60e-04, 2.46e-04, 3.66e-04, 3.94e-04, 1.44e-04, 1.98e-04, 3.49e-04, 3.64e-03, 1.03e-04]    [2.60e-04, 2.46e-04, 3.66e-04, 3.94e-04, 1.44e-04, 1.98e-04, 3.49e-04, 3.64e-03, 1.03e-04]    []  
140000    [2.69e-04, 1.93e-04, 3.48e-04, 2.05e-04, 1.53e-04, 1.08e-04, 3.37e-04, 3.50e-03, 9.20e-05]    [2.69e-04, 1.93e-04, 3.48e-04, 2.05e-04, 1.53e-04, 1.08e-04, 3.37e-04, 3.50e-03, 9.20e-05]    []  
150000    [1.27e-04, 1.45e-04, 1.60e-04, 1.43e-04, 1.04e-04, 1.14e-04, 3.26e-04, 3.34e-03, 8.64e-05]    [1.27e-04, 1.45e-04, 1.60e-04, 1.43e-04, 1.04e-04, 1.14e-04, 3.26e-04, 3.34e-03, 8.64e-05]    []  
160000    [1.56e-04, 1.41e-04, 2.06e-04, 1.43e-04, 1.20e-04, 9.55e-05, 3.25e-04, 3.29e-03, 7.93e-05]    [1.56e-04, 1.41e-04, 2.06e-04, 1.43e-04, 1.20e-04, 9.55e-05, 3.25e-04, 3.29e-03, 7.93e-05]    []  
170000    [2.84e-04, 1.64e-04, 3.28e-04, 3.25e-04, 1.47e-04, 1.44e-04, 3.23e-04, 3.31e-03, 7.81e-05]    [2.84e-04, 1.64e-04, 3.28e-04, 3.25e-04, 1.47e-04, 1.44e-04, 3.23e-04, 3.31e-03, 7.81e-05]    []  
180000    [5.66e-04, 2.94e-04, 8.29e-04, 4.82e-04, 2.22e-04, 2.96e-04, 3.36e-04, 3.30e-03, 7.47e-05]    [5.66e-04, 2.94e-04, 8.29e-04, 4.82e-04, 2.22e-04, 2.96e-04, 3.36e-04, 3.30e-03, 7.47e-05]    []  
190000    [2.39e-04, 2.38e-04, 3.07e-04, 3.11e-04, 1.11e-04, 1.49e-04, 3.24e-04, 3.24e-03, 7.36e-05]    [2.39e-04, 2.38e-04, 3.07e-04, 3.11e-04, 1.11e-04, 1.49e-04, 3.24e-04, 3.24e-03, 7.36e-05]    []  
200000    [2.31e-04, 1.71e-04, 2.39e-04, 2.09e-04, 1.12e-04, 1.03e-04, 3.13e-04, 3.15e-03, 6.50e-05]    [2.31e-04, 1.71e-04, 2.39e-04, 2.09e-04, 1.12e-04, 1.03e-04, 3.13e-04, 3.15e-03, 6.50e-05]    []  

Best model at step 150000:
  train loss: 4.54e-03
  test loss: 4.54e-03
  test metric: []

'train' took 35188.204568 s

