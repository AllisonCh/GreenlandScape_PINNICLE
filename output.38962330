Set the default float type to float64
add Fourier feature transform to input transform
add output transform with [-1.92774354e-06 -1.92774354e-06 -1.92774354e-06 -1.92774354e-06
 -1.00000000e+03  1.00000000e+01  1.00000000e-02] and [1.92774354e-06 1.92774354e-06 1.92774354e-06 1.92774354e-06
 4.00000000e+03 4.00000000e+03 1.00000000e+04]
Parameters: 
	TrainingParameter: 
		epochs:	150000
		optimizer:	adam
		loss_functions:	['MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE']
		additional_loss:	{}
		learning_rate:	0.001
		loss_weights:	[2e-14, 2e-14, 2e-14, 2e-14, 99451929600.0, 99451929600.0, 99451929600.0, 99451929600.0, 1e-06, 1e-07, 5e-09]
		has_callbacks:	False
		min_delta:	None
		patience:	None
		period:	None
		checkpoint:	False
		save_path:	./PINNs/UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_1G
		is_save:	True
		is_plot:	True
	DomainParameter: 
		shapefile:	./UpperJakobshavn_17_11.exp
		num_collocation_points:	16000
		time_dependent:	False
		start_time:	0
		end_time:	0
	DataParameter: 
		ISSM:
			data_path:	./Models/UpperJakobshavn_issm2025-Jan-17_1.mat
			data_size:	{'u': 8000, 'v': 8000, 's': 8000, 'H': None, 'C': 8000}
			name_map:	{'u': 'u', 'v': 'v', 's': 's', 'H': 'H', 'C': 'C'}
			X_map:	{'x': 'x', 'y': 'y', 't': 't'}
			source:	ISSM
			default_time:	None

		ft:
			data_path:	./UpperJakobshavn_xyz_500.mat
			data_size:	{'H': 8000}
			name_map:	{'H': 'thickness'}
			X_map:	{'x': 'x', 'y': 'y'}
			source:	mat
			default_time:	None

		velbase:
			data_path:	./UpJak_vel_base_ms.mat
			data_size:	{'u_base': 8000, 'v_base': 8000}
			name_map:	{'u_base': 'md_u_base', 'v_base': 'md_v_base'}
			X_map:	{'x': 'x', 'y': 'y'}
			source:	mat
			default_time:	None

	NNParameter: 
		input_variables:	['x', 'y']
		output_variables:	['u', 'v', 'u_base', 'v_base', 's', 'H', 'C']
		num_neurons:	20
		num_layers:	6
		activation:	tanh
		initializer:	Glorot uniform
		fft:	True
		num_fourier_feature:	30
		sigma:	5
		B:	None
		is_parallel:	False
		input_lb:	[   22000. -2259000.]
		input_ub:	[  172000. -2109000.]
		output_lb:	[-1.92774354e-06 -1.92774354e-06 -1.92774354e-06 -1.92774354e-06
 -1.00000000e+03  1.00000000e+01  1.00000000e-02]
		output_ub:	[1.92774354e-06 1.92774354e-06 1.92774354e-06 1.92774354e-06
 4.00000000e+03 4.00000000e+03 1.00000000e+04]
		input_size:	2
		output_size:	7
	PhysicsParameter: 
		MOLHO:
			rhoi:	917.0
			rhow:	1023.0
			g:	9.81
			yts:	31536000.0
			variable_lb:	[-1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1000.0, 10.0, 0.01]
			variable_ub:	[1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 4000.0, 4000.0, 10000.0]
			input:	['x', 'y']
			output:	['u', 'v', 'u_base', 'v_base', 's', 'H', 'C']
			output_lb:	[-1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1000.0, 10.0, 0.01]
			output_ub:	[1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 4000.0, 4000.0, 10000.0]
			data_weights:	[99451929600.0, 99451929600.0, 99451929600.0, 99451929600.0, 1e-06, 1e-07, 5e-09]
			residuals:	['fMOLHO 1', 'fMOLHO 2', 'fMOLHO base 1', 'fMOLHO base 2']
			pde_weights:	[2e-14, 2e-14, 2e-14, 2e-14]
			scalar_variables:	{'n': 3.0, 'B': 200000000.0}


Compiling model...
'compile' took 0.005675 s

Set the default float type to float64
add Fourier feature transform to input transform
add output transform with [-1.92774354e-06 -1.92774354e-06 -1.92774354e-06 -1.92774354e-06
 -1.00000000e+03  1.00000000e+01  1.00000000e-02] and [1.92774354e-06 1.92774354e-06 1.92774354e-06 1.92774354e-06
 4.00000000e+03 4.00000000e+03 1.00000000e+04]
Parameters: 
	TrainingParameter: 
		epochs:	150000
		optimizer:	adam
		loss_functions:	['MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE']
		additional_loss:	{}
		learning_rate:	0.001
		loss_weights:	[2e-14, 2e-14, 2e-14, 2e-14, 99451929600.0, 99451929600.0, 99451929600.0, 99451929600.0, 1e-06, 1e-07, 5e-09]
		has_callbacks:	False
		min_delta:	None
		patience:	None
		period:	None
		checkpoint:	False
		save_path:	./PINNs/UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_2G
		is_save:	True
		is_plot:	True
	DomainParameter: 
		shapefile:	./UpperJakobshavn_17_11.exp
		num_collocation_points:	16000
		time_dependent:	False
		start_time:	0
		end_time:	0
	DataParameter: 
		ISSM:
			data_path:	./Models/UpperJakobshavn_issm2025-Jan-17_1.mat
			data_size:	{'u': 8000, 'v': 8000, 's': 8000, 'H': None, 'C': 8000}
			name_map:	{'u': 'u', 'v': 'v', 's': 's', 'H': 'H', 'C': 'C'}
			X_map:	{'x': 'x', 'y': 'y', 't': 't'}
			source:	ISSM
			default_time:	None

		ft:
			data_path:	./UpperJakobshavn_xyz_500.mat
			data_size:	{'H': 8000}
			name_map:	{'H': 'thickness'}
			X_map:	{'x': 'x', 'y': 'y'}
			source:	mat
			default_time:	None

		velbase:
			data_path:	./UpJak_vel_base_ms.mat
			data_size:	{'u_base': 8000, 'v_base': 8000}
			name_map:	{'u_base': 'md_u_base', 'v_base': 'md_v_base'}
			X_map:	{'x': 'x', 'y': 'y'}
			source:	mat
			default_time:	None

	NNParameter: 
		input_variables:	['x', 'y']
		output_variables:	['u', 'v', 'u_base', 'v_base', 's', 'H', 'C']
		num_neurons:	20
		num_layers:	6
		activation:	tanh
		initializer:	Glorot uniform
		fft:	True
		num_fourier_feature:	30
		sigma:	5
		B:	None
		is_parallel:	False
		input_lb:	[   22000. -2259000.]
		input_ub:	[  172000. -2109000.]
		output_lb:	[-1.92774354e-06 -1.92774354e-06 -1.92774354e-06 -1.92774354e-06
 -1.00000000e+03  1.00000000e+01  1.00000000e-02]
		output_ub:	[1.92774354e-06 1.92774354e-06 1.92774354e-06 1.92774354e-06
 4.00000000e+03 4.00000000e+03 1.00000000e+04]
		input_size:	2
		output_size:	7
	PhysicsParameter: 
		MOLHO:
			rhoi:	917.0
			rhow:	1023.0
			g:	9.81
			yts:	31536000.0
			variable_lb:	[-1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1000.0, 10.0, 0.01]
			variable_ub:	[1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 4000.0, 4000.0, 10000.0]
			input:	['x', 'y']
			output:	['u', 'v', 'u_base', 'v_base', 's', 'H', 'C']
			output_lb:	[-1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1000.0, 10.0, 0.01]
			output_ub:	[1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 4000.0, 4000.0, 10000.0]
			data_weights:	[99451929600.0, 99451929600.0, 99451929600.0, 99451929600.0, 1e-06, 1e-07, 5e-09]
			residuals:	['fMOLHO 1', 'fMOLHO 2', 'fMOLHO base 1', 'fMOLHO base 2']
			pde_weights:	[2e-14, 2e-14, 2e-14, 2e-14]
			scalar_variables:	{'n': 3.0, 'B': 250000000.0}


Compiling model...
'compile' took 0.005737 s

Set the default float type to float64
add Fourier feature transform to input transform
add output transform with [-1.92774354e-06 -1.92774354e-06 -1.92774354e-06 -1.92774354e-06
 -1.00000000e+03  1.00000000e+01  1.00000000e-02] and [1.92774354e-06 1.92774354e-06 1.92774354e-06 1.92774354e-06
 4.00000000e+03 4.00000000e+03 1.00000000e+04]
Parameters: 
	TrainingParameter: 
		epochs:	150000
		optimizer:	adam
		loss_functions:	['MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE', 'MSE']
		additional_loss:	{}
		learning_rate:	0.001
		loss_weights:	[2e-14, 2e-14, 2e-14, 2e-14, 99451929600.0, 99451929600.0, 99451929600.0, 99451929600.0, 1e-06, 1e-07, 5e-09]
		has_callbacks:	False
		min_delta:	None
		patience:	None
		period:	None
		checkpoint:	False
		save_path:	./PINNs/UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_3G
		is_save:	True
		is_plot:	True
	DomainParameter: 
		shapefile:	./UpperJakobshavn_17_11.exp
		num_collocation_points:	16000
		time_dependent:	False
		start_time:	0
		end_time:	0
	DataParameter: 
		ISSM:
			data_path:	./Models/UpperJakobshavn_issm2025-Jan-17_1.mat
			data_size:	{'u': 8000, 'v': 8000, 's': 8000, 'H': None, 'C': 8000}
			name_map:	{'u': 'u', 'v': 'v', 's': 's', 'H': 'H', 'C': 'C'}
			X_map:	{'x': 'x', 'y': 'y', 't': 't'}
			source:	ISSM
			default_time:	None

		ft:
			data_path:	./UpperJakobshavn_xyz_500.mat
			data_size:	{'H': 8000}
			name_map:	{'H': 'thickness'}
			X_map:	{'x': 'x', 'y': 'y'}
			source:	mat
			default_time:	None

		velbase:
			data_path:	./UpJak_vel_base_ms.mat
			data_size:	{'u_base': 8000, 'v_base': 8000}
			name_map:	{'u_base': 'md_u_base', 'v_base': 'md_v_base'}
			X_map:	{'x': 'x', 'y': 'y'}
			source:	mat
			default_time:	None

	NNParameter: 
		input_variables:	['x', 'y']
		output_variables:	['u', 'v', 'u_base', 'v_base', 's', 'H', 'C']
		num_neurons:	20
		num_layers:	6
		activation:	tanh
		initializer:	Glorot uniform
		fft:	True
		num_fourier_feature:	30
		sigma:	5
		B:	None
		is_parallel:	False
		input_lb:	[   22000. -2259000.]
		input_ub:	[  172000. -2109000.]
		output_lb:	[-1.92774354e-06 -1.92774354e-06 -1.92774354e-06 -1.92774354e-06
 -1.00000000e+03  1.00000000e+01  1.00000000e-02]
		output_ub:	[1.92774354e-06 1.92774354e-06 1.92774354e-06 1.92774354e-06
 4.00000000e+03 4.00000000e+03 1.00000000e+04]
		input_size:	2
		output_size:	7
	PhysicsParameter: 
		MOLHO:
			rhoi:	917.0
			rhow:	1023.0
			g:	9.81
			yts:	31536000.0
			variable_lb:	[-1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1000.0, 10.0, 0.01]
			variable_ub:	[1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 4000.0, 4000.0, 10000.0]
			input:	['x', 'y']
			output:	['u', 'v', 'u_base', 'v_base', 's', 'H', 'C']
			output_lb:	[-1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1.927743544750083e-06, -1000.0, 10.0, 0.01]
			output_ub:	[1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 1.927743544750083e-06, 4000.0, 4000.0, 10000.0]
			data_weights:	[99451929600.0, 99451929600.0, 99451929600.0, 99451929600.0, 1e-06, 1e-07, 5e-09]
			residuals:	['fMOLHO 1', 'fMOLHO 2', 'fMOLHO base 1', 'fMOLHO base 2']
			pde_weights:	[2e-14, 2e-14, 2e-14, 2e-14]
			scalar_variables:	{'n': 3.0, 'B': 150000000.0}


Compiling model...
'compile' took 0.010935 s

Training model...

Step      Train loss                                                                                                        Test loss                                                                                                         Test metric
0         [2.60e-02, 2.23e-02, 1.52e-02, 1.37e-02, 1.69e-01, 5.37e-02, 2.88e-02, 2.88e-02, 2.61e+00, 5.68e-02, 3.76e-02]    [2.60e-02, 2.23e-02, 1.52e-02, 1.37e-02, 1.69e-01, 5.37e-02, 2.88e-02, 2.88e-02, 2.61e+00, 5.68e-02, 3.76e-02]    []  
Training model...

Step      Train loss                                                                                                        Test loss                                                                                                         Test metric
0         [2.48e-02, 4.57e-02, 1.59e-02, 2.37e-02, 1.39e-01, 3.81e-02, 2.61e-02, 3.48e-02, 1.87e+00, 1.43e-01, 6.98e-02]    [2.48e-02, 4.57e-02, 1.59e-02, 2.37e-02, 1.39e-01, 3.81e-02, 2.61e-02, 3.48e-02, 1.87e+00, 1.43e-01, 6.98e-02]    []  
Training model...

Step      Train loss                                                                                                        Test loss                                                                                                         Test metric
0         [9.63e-03, 2.16e-02, 5.64e-03, 1.32e-02, 9.12e-02, 2.01e-02, 4.36e-02, 7.85e-02, 1.63e+00, 4.69e-02, 2.11e-02]    [9.63e-03, 2.16e-02, 5.64e-03, 1.32e-02, 9.12e-02, 2.01e-02, 4.36e-02, 7.85e-02, 1.63e+00, 4.69e-02, 2.11e-02]    []  
10000     [5.63e-05, 1.58e-05, 8.66e-05, 1.99e-05, 9.52e-06, 9.42e-06, 3.36e-06, 1.11e-06, 2.26e-05, 3.44e-04, 5.92e-05]    [5.63e-05, 1.58e-05, 8.66e-05, 1.99e-05, 9.52e-06, 9.42e-06, 3.36e-06, 1.11e-06, 2.26e-05, 3.44e-04, 5.92e-05]    []  
10000     [5.58e-05, 1.54e-05, 8.13e-05, 1.84e-05, 8.09e-06, 1.11e-05, 2.94e-06, 1.48e-06, 2.14e-05, 3.35e-04, 4.90e-05]    [5.58e-05, 1.54e-05, 8.13e-05, 1.84e-05, 8.09e-06, 1.11e-05, 2.94e-06, 1.48e-06, 2.14e-05, 3.35e-04, 4.90e-05]    []  
10000     [5.51e-05, 1.52e-05, 9.09e-05, 2.03e-05, 6.92e-06, 1.05e-05, 3.25e-06, 1.25e-06, 2.75e-05, 3.61e-04, 4.68e-05]    [5.51e-05, 1.52e-05, 9.09e-05, 2.03e-05, 6.92e-06, 1.05e-05, 3.25e-06, 1.25e-06, 2.75e-05, 3.61e-04, 4.68e-05]    []  
20000     [5.08e-05, 1.35e-05, 7.67e-05, 1.70e-05, 5.72e-06, 8.62e-06, 2.22e-06, 9.93e-07, 2.00e-05, 2.55e-04, 2.75e-05]    [5.08e-05, 1.35e-05, 7.67e-05, 1.70e-05, 5.72e-06, 8.62e-06, 2.22e-06, 9.93e-07, 2.00e-05, 2.55e-04, 2.75e-05]    []  
20000     [5.13e-05, 1.39e-05, 8.23e-05, 1.82e-05, 7.16e-06, 8.24e-06, 2.21e-06, 8.21e-07, 2.07e-05, 2.62e-04, 3.66e-05]    [5.13e-05, 1.39e-05, 8.23e-05, 1.82e-05, 7.16e-06, 8.24e-06, 2.21e-06, 8.21e-07, 2.07e-05, 2.62e-04, 3.66e-05]    []  
20000     [5.08e-05, 1.36e-05, 8.78e-05, 1.91e-05, 5.65e-06, 7.75e-06, 2.21e-06, 7.37e-07, 1.96e-05, 2.66e-04, 2.90e-05]    [5.08e-05, 1.36e-05, 8.78e-05, 1.91e-05, 5.65e-06, 7.75e-06, 2.21e-06, 7.37e-07, 1.96e-05, 2.66e-04, 2.90e-05]    []  
30000     [5.27e-05, 1.29e-05, 7.78e-05, 1.68e-05, 5.04e-06, 6.99e-06, 2.14e-06, 9.42e-07, 3.03e-05, 5.72e-04, 2.41e-05]    [5.27e-05, 1.29e-05, 7.78e-05, 1.68e-05, 5.04e-06, 6.99e-06, 2.14e-06, 9.42e-07, 3.03e-05, 5.72e-04, 2.41e-05]    []  
30000     [5.11e-05, 1.31e-05, 8.17e-05, 1.79e-05, 6.06e-06, 7.91e-06, 2.04e-06, 9.41e-07, 2.40e-05, 3.90e-04, 2.96e-05]    [5.11e-05, 1.31e-05, 8.17e-05, 1.79e-05, 6.06e-06, 7.91e-06, 2.04e-06, 9.41e-07, 2.40e-05, 3.90e-04, 2.96e-05]    []  
30000     [4.64e-05, 1.29e-05, 8.45e-05, 1.83e-05, 5.24e-06, 7.24e-06, 2.22e-06, 6.05e-07, 2.44e-05, 3.39e-04, 2.36e-05]    [4.64e-05, 1.29e-05, 8.45e-05, 1.83e-05, 5.24e-06, 7.24e-06, 2.22e-06, 6.05e-07, 2.44e-05, 3.39e-04, 2.36e-05]    []  
40000     [4.78e-05, 1.20e-05, 7.39e-05, 1.58e-05, 4.30e-06, 6.25e-06, 1.95e-06, 6.26e-07, 1.94e-05, 2.58e-04, 1.67e-05]    [4.78e-05, 1.20e-05, 7.39e-05, 1.58e-05, 4.30e-06, 6.25e-06, 1.95e-06, 6.26e-07, 1.94e-05, 2.58e-04, 1.67e-05]    []  
40000     [4.70e-05, 1.24e-05, 7.90e-05, 1.71e-05, 5.20e-06, 6.93e-06, 1.99e-06, 6.63e-07, 1.91e-05, 2.13e-04, 2.35e-05]    [4.70e-05, 1.24e-05, 7.90e-05, 1.71e-05, 5.20e-06, 6.93e-06, 1.99e-06, 6.63e-07, 1.91e-05, 2.13e-04, 2.35e-05]    []  
40000     [4.68e-05, 1.26e-05, 8.46e-05, 1.82e-05, 4.59e-06, 6.35e-06, 2.05e-06, 6.51e-07, 1.96e-05, 2.28e-04, 2.00e-05]    [4.68e-05, 1.26e-05, 8.46e-05, 1.82e-05, 4.59e-06, 6.35e-06, 2.05e-06, 6.51e-07, 1.96e-05, 2.28e-04, 2.00e-05]    []  
50000     [4.55e-05, 1.16e-05, 7.21e-05, 1.55e-05, 4.14e-06, 5.91e-06, 1.94e-06, 6.08e-07, 1.83e-05, 2.22e-04, 1.44e-05]    [4.55e-05, 1.16e-05, 7.21e-05, 1.55e-05, 4.14e-06, 5.91e-06, 1.94e-06, 6.08e-07, 1.83e-05, 2.22e-04, 1.44e-05]    []  
50000     [4.80e-05, 1.29e-05, 7.96e-05, 1.73e-05, 4.87e-06, 6.10e-06, 1.92e-06, 5.79e-07, 4.30e-05, 3.79e-04, 2.00e-05]    [4.80e-05, 1.29e-05, 7.96e-05, 1.73e-05, 4.87e-06, 6.10e-06, 1.92e-06, 5.79e-07, 4.30e-05, 3.79e-04, 2.00e-05]    []  
50000     [4.68e-05, 1.22e-05, 8.44e-05, 1.80e-05, 4.04e-06, 6.05e-06, 1.92e-06, 7.31e-07, 1.84e-05, 2.10e-04, 1.70e-05]    [4.68e-05, 1.22e-05, 8.44e-05, 1.80e-05, 4.04e-06, 6.05e-06, 1.92e-06, 7.31e-07, 1.84e-05, 2.10e-04, 1.70e-05]    []  
60000     [4.53e-05, 1.10e-05, 7.14e-05, 1.52e-05, 4.11e-06, 5.91e-06, 1.70e-06, 7.47e-07, 1.93e-05, 2.00e-04, 1.33e-05]    [4.53e-05, 1.10e-05, 7.14e-05, 1.52e-05, 4.11e-06, 5.91e-06, 1.70e-06, 7.47e-07, 1.93e-05, 2.00e-04, 1.33e-05]    []  
60000     [4.49e-05, 1.18e-05, 7.69e-05, 1.65e-05, 4.41e-06, 5.31e-06, 1.87e-06, 6.32e-07, 1.84e-05, 1.89e-04, 1.69e-05]    [4.49e-05, 1.18e-05, 7.69e-05, 1.65e-05, 4.41e-06, 5.31e-06, 1.87e-06, 6.32e-07, 1.84e-05, 1.89e-04, 1.69e-05]    []  
60000     [4.52e-05, 1.21e-05, 8.32e-05, 1.78e-05, 3.78e-06, 5.90e-06, 1.97e-06, 6.17e-07, 1.90e-05, 2.04e-04, 1.49e-05]    [4.52e-05, 1.21e-05, 8.32e-05, 1.78e-05, 3.78e-06, 5.90e-06, 1.97e-06, 6.17e-07, 1.90e-05, 2.04e-04, 1.49e-05]    []  
70000     [4.36e-05, 1.11e-05, 7.02e-05, 1.50e-05, 3.99e-06, 5.96e-06, 1.88e-06, 5.92e-07, 1.80e-05, 1.99e-04, 1.26e-05]    [4.36e-05, 1.11e-05, 7.02e-05, 1.50e-05, 3.99e-06, 5.96e-06, 1.88e-06, 5.92e-07, 1.80e-05, 1.99e-04, 1.26e-05]    []  
70000     [4.44e-05, 1.15e-05, 7.61e-05, 1.63e-05, 4.26e-06, 4.88e-06, 1.73e-06, 6.68e-07, 1.82e-05, 1.79e-04, 1.52e-05]    [4.44e-05, 1.15e-05, 7.61e-05, 1.63e-05, 4.26e-06, 4.88e-06, 1.73e-06, 6.68e-07, 1.82e-05, 1.79e-04, 1.52e-05]    []  
70000     [4.51e-05, 1.21e-05, 8.31e-05, 1.77e-05, 3.74e-06, 5.59e-06, 1.96e-06, 5.91e-07, 1.85e-05, 1.93e-04, 1.36e-05]    [4.51e-05, 1.21e-05, 8.31e-05, 1.77e-05, 3.74e-06, 5.59e-06, 1.96e-06, 5.91e-07, 1.85e-05, 1.93e-04, 1.36e-05]    []  
80000     [4.34e-05, 1.08e-05, 6.99e-05, 1.48e-05, 3.85e-06, 5.71e-06, 1.78e-06, 6.08e-07, 1.78e-05, 1.78e-04, 1.13e-05]    [4.34e-05, 1.08e-05, 6.99e-05, 1.48e-05, 3.85e-06, 5.71e-06, 1.78e-06, 6.08e-07, 1.78e-05, 1.78e-04, 1.13e-05]    []  
80000     [4.33e-05, 1.15e-05, 7.53e-05, 1.61e-05, 4.30e-06, 4.70e-06, 1.82e-06, 5.90e-07, 1.81e-05, 1.71e-04, 1.38e-05]    [4.33e-05, 1.15e-05, 7.53e-05, 1.61e-05, 4.30e-06, 4.70e-06, 1.82e-06, 5.90e-07, 1.81e-05, 1.71e-04, 1.38e-05]    []  
80000     [4.25e-05, 1.14e-05, 8.08e-05, 1.72e-05, 3.68e-06, 5.29e-06, 1.94e-06, 6.09e-07, 2.53e-05, 2.52e-04, 1.30e-05]    [4.25e-05, 1.14e-05, 8.08e-05, 1.72e-05, 3.68e-06, 5.29e-06, 1.94e-06, 6.09e-07, 2.53e-05, 2.52e-04, 1.30e-05]    []  
90000     [4.29e-05, 1.10e-05, 6.95e-05, 1.47e-05, 3.71e-06, 5.46e-06, 1.91e-06, 5.17e-07, 1.78e-05, 1.71e-04, 1.05e-05]    [4.29e-05, 1.10e-05, 6.95e-05, 1.47e-05, 3.71e-06, 5.46e-06, 1.91e-06, 5.17e-07, 1.78e-05, 1.71e-04, 1.05e-05]    []  
90000     [4.27e-05, 1.13e-05, 7.48e-05, 1.59e-05, 4.40e-06, 4.53e-06, 1.81e-06, 5.84e-07, 1.83e-05, 1.63e-04, 1.31e-05]    [4.27e-05, 1.13e-05, 7.48e-05, 1.59e-05, 4.40e-06, 4.53e-06, 1.81e-06, 5.84e-07, 1.83e-05, 1.63e-04, 1.31e-05]    []  
90000     [4.43e-05, 1.18e-05, 8.23e-05, 1.75e-05, 3.56e-06, 5.04e-06, 1.88e-06, 6.13e-07, 1.85e-05, 1.80e-04, 1.18e-05]    [4.43e-05, 1.18e-05, 8.23e-05, 1.75e-05, 3.56e-06, 5.04e-06, 1.88e-06, 6.13e-07, 1.85e-05, 1.80e-04, 1.18e-05]    []  
100000    [4.32e-05, 1.00e-05, 6.89e-05, 1.45e-05, 3.68e-06, 5.40e-06, 1.46e-06, 8.50e-07, 3.46e-05, 2.08e-04, 1.01e-05]    [4.32e-05, 1.00e-05, 6.89e-05, 1.45e-05, 3.68e-06, 5.40e-06, 1.46e-06, 8.50e-07, 3.46e-05, 2.08e-04, 1.01e-05]    []  
100000    [4.12e-05, 1.08e-05, 7.37e-05, 1.56e-05, 4.39e-06, 4.75e-06, 1.75e-06, 6.05e-07, 2.11e-05, 3.12e-04, 1.37e-05]    [4.12e-05, 1.08e-05, 7.37e-05, 1.56e-05, 4.39e-06, 4.75e-06, 1.75e-06, 6.05e-07, 2.11e-05, 3.12e-04, 1.37e-05]    []  
100000    [4.57e-05, 1.18e-05, 8.35e-05, 1.76e-05, 3.51e-06, 5.01e-06, 1.79e-06, 6.55e-07, 1.76e-05, 1.95e-04, 1.10e-05]    [4.57e-05, 1.18e-05, 8.35e-05, 1.76e-05, 3.51e-06, 5.01e-06, 1.79e-06, 6.55e-07, 1.76e-05, 1.95e-04, 1.10e-05]    []  
110000    [4.20e-05, 1.05e-05, 6.87e-05, 1.44e-05, 3.36e-06, 4.81e-06, 1.77e-06, 5.55e-07, 1.79e-05, 1.57e-04, 9.38e-06]    [4.20e-05, 1.05e-05, 6.87e-05, 1.44e-05, 3.36e-06, 4.81e-06, 1.77e-06, 5.55e-07, 1.79e-05, 1.57e-04, 9.38e-06]    []  
110000    [4.21e-05, 1.10e-05, 7.42e-05, 1.57e-05, 4.08e-06, 4.42e-06, 1.74e-06, 5.81e-07, 1.77e-05, 1.51e-04, 1.18e-05]    [4.21e-05, 1.10e-05, 7.42e-05, 1.57e-05, 4.08e-06, 4.42e-06, 1.74e-06, 5.81e-07, 1.77e-05, 1.51e-04, 1.18e-05]    []  
110000    [4.34e-05, 1.16e-05, 8.16e-05, 1.73e-05, 3.51e-06, 4.88e-06, 1.90e-06, 5.70e-07, 1.84e-05, 1.69e-04, 1.03e-05]    [4.34e-05, 1.16e-05, 8.16e-05, 1.73e-05, 3.51e-06, 4.88e-06, 1.90e-06, 5.70e-07, 1.84e-05, 1.69e-04, 1.03e-05]    []  
120000    [4.15e-05, 1.04e-05, 6.83e-05, 1.44e-05, 3.24e-06, 4.62e-06, 1.76e-06, 5.49e-07, 1.79e-05, 1.52e-04, 9.45e-06]    [4.15e-05, 1.04e-05, 6.83e-05, 1.44e-05, 3.24e-06, 4.62e-06, 1.76e-06, 5.49e-07, 1.79e-05, 1.52e-04, 9.45e-06]    []  
120000    [4.09e-05, 1.08e-05, 7.34e-05, 1.55e-05, 3.89e-06, 4.50e-06, 1.80e-06, 5.41e-07, 1.88e-05, 1.65e-04, 1.16e-05]    [4.09e-05, 1.08e-05, 7.34e-05, 1.55e-05, 3.89e-06, 4.50e-06, 1.80e-06, 5.41e-07, 1.88e-05, 1.65e-04, 1.16e-05]    []  
120000    [4.40e-05, 1.10e-05, 8.17e-05, 1.71e-05, 3.58e-06, 4.81e-06, 1.66e-06, 7.21e-07, 1.75e-05, 1.68e-04, 9.83e-06]    [4.40e-05, 1.10e-05, 8.17e-05, 1.71e-05, 3.58e-06, 4.81e-06, 1.66e-06, 7.21e-07, 1.75e-05, 1.68e-04, 9.83e-06]    []  
130000    [4.12e-05, 1.01e-05, 6.77e-05, 1.42e-05, 3.22e-06, 4.51e-06, 1.62e-06, 6.16e-07, 2.01e-05, 1.49e-04, 9.41e-06]    [4.12e-05, 1.01e-05, 6.77e-05, 1.42e-05, 3.22e-06, 4.51e-06, 1.62e-06, 6.16e-07, 2.01e-05, 1.49e-04, 9.41e-06]    []  
130000    [4.25e-05, 1.04e-05, 7.40e-05, 1.56e-05, 3.72e-06, 4.58e-06, 1.43e-06, 7.33e-07, 1.70e-05, 1.44e-04, 1.07e-05]    [4.25e-05, 1.04e-05, 7.40e-05, 1.56e-05, 3.72e-06, 4.58e-06, 1.43e-06, 7.33e-07, 1.70e-05, 1.44e-04, 1.07e-05]    []  
130000    [4.34e-05, 1.11e-05, 8.13e-05, 1.70e-05, 3.62e-06, 4.77e-06, 1.75e-06, 6.52e-07, 1.83e-05, 1.62e-04, 9.55e-06]    [4.34e-05, 1.11e-05, 8.13e-05, 1.70e-05, 3.62e-06, 4.77e-06, 1.75e-06, 6.52e-07, 1.83e-05, 1.62e-04, 9.55e-06]    []  
140000    [4.09e-05, 1.01e-05, 6.78e-05, 1.42e-05, 3.14e-06, 4.53e-06, 1.67e-06, 5.85e-07, 1.82e-05, 1.47e-04, 9.90e-06]    [4.09e-05, 1.01e-05, 6.78e-05, 1.42e-05, 3.14e-06, 4.53e-06, 1.67e-06, 5.85e-07, 1.82e-05, 1.47e-04, 9.90e-06]    []  
140000    [4.08e-05, 1.07e-05, 7.31e-05, 1.54e-05, 3.58e-06, 4.58e-06, 1.71e-06, 5.56e-07, 1.76e-05, 1.40e-04, 1.04e-05]    [4.08e-05, 1.07e-05, 7.31e-05, 1.54e-05, 3.58e-06, 4.58e-06, 1.71e-06, 5.56e-07, 1.76e-05, 1.40e-04, 1.04e-05]    []  
140000    [4.20e-05, 1.08e-05, 8.01e-05, 1.67e-05, 3.69e-06, 4.79e-06, 1.70e-06, 6.45e-07, 1.79e-05, 2.09e-04, 9.46e-06]    [4.20e-05, 1.08e-05, 8.01e-05, 1.67e-05, 3.69e-06, 4.79e-06, 1.70e-06, 6.45e-07, 1.79e-05, 2.09e-04, 9.46e-06]    []  
150000    [4.01e-05, 9.57e-06, 6.70e-05, 1.40e-05, 3.05e-06, 5.08e-06, 1.53e-06, 6.76e-07, 2.48e-05, 1.38e-04, 1.24e-05]    [4.01e-05, 9.57e-06, 6.70e-05, 1.40e-05, 3.05e-06, 5.08e-06, 1.53e-06, 6.76e-07, 2.48e-05, 1.38e-04, 1.24e-05]    []  

Best model at step 150000:
  train loss: 3.16e-04
  test loss: 3.16e-04
  test metric: []

'train' took 45997.264597 s

150000    [4.06e-05, 1.05e-05, 7.28e-05, 1.54e-05, 3.50e-06, 4.48e-06, 1.62e-06, 5.94e-07, 1.75e-05, 1.39e-04, 1.01e-05]    [4.06e-05, 1.05e-05, 7.28e-05, 1.54e-05, 3.50e-06, 4.48e-06, 1.62e-06, 5.94e-07, 1.75e-05, 1.39e-04, 1.01e-05]    []  

Best model at step 150000:
  train loss: 3.16e-04
  test loss: 3.16e-04
  test metric: []

'train' took 46007.231863 s

Use filtered surface speed with elevation azimuth and calculate along-flow surface slope...
Use filtered surface speed with elevation azimuth and calculate along-flow surface slope...
Using already loaded history
total loss for  UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_3G =  0.0003160925278309269  at step 15
UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_3G rmse_H_pred:  42.97469318057054
UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_3G rmse_H_BM5:  55.891423229016304
UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_3G  rmses :  {'u': 0.1764656338797334, 'v': 0.23272287515913367, 'u_base': 0.12559550647158096, 'v_base': 0.08136083086761844, 's': 5.082226699615966, 'H': 963.065313078836, 'C': 52.73112494913622}
150000    [4.25e-05, 1.10e-05, 8.05e-05, 1.69e-05, 3.69e-06, 4.78e-06, 1.73e-06, 6.26e-07, 1.78e-05, 1.52e-04, 9.02e-06]    [4.25e-05, 1.10e-05, 8.05e-05, 1.69e-05, 3.69e-06, 4.78e-06, 1.73e-06, 6.26e-07, 1.78e-05, 1.52e-04, 9.02e-06]    []  

Best model at step 150000:
  train loss: 3.41e-04
  test loss: 3.41e-04
  test metric: []

'train' took 46061.944967 s

Use filtered surface speed with elevation azimuth and calculate along-flow surface slope...
Use filtered surface speed with elevation azimuth and calculate along-flow surface slope...
Using already loaded history
total loss for  UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_1G =  0.0003157960769386651  at step 15
UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_1G rmse_H_pred:  42.991383595953835
UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_1G rmse_H_BM5:  55.891423229016304
UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_1G  rmses :  {'u': 0.19033639051150208, 'v': 0.22070819116776916, 'u_base': 0.12901171420665666, 'v_base': 0.0761334885557822, 's': 4.2629687100915294, 'H': 923.8698946622168, 'C': 48.03902065325709}
Use filtered surface speed with elevation azimuth and calculate along-flow surface slope...
Use filtered surface speed with elevation azimuth and calculate along-flow surface slope...
Using already loaded history
total loss for  UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_2G =  0.0003406332598044207  at step 15
UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_2G rmse_H_pred:  44.60364418495086
UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_2G rmse_H_BM5:  55.891423229016304
UpperJakobshavn_issm2025-Jan-17_1_pinn25-Feb-17_2G  rmses :  {'u': 0.19775977078406376, 'v': 0.22852575681166287, 'u_base': 0.13306640925354032, 'v_base': 0.07807256724465003, 's': 4.311923574156705, 'H': 860.3350117983097, 'C': 47.063065127614394}
